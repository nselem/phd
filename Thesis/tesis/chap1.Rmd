---
output: pdf_document
---
<!--
The {#rmd-basics} text after the chapter declaration will allow us to link throughout the document back to the beginning of Chapter 1.  These labels will automatically be generated (if not specified) by changing the spaces to hyphens and capital letters to lowercase.  Look for the reference to this label at the beginning of Chapter 2.
-->

```{r load_pkgs, message = FALSE}
# List of packages required for this analysis
pkg <- c("dplyr", "ggplot2", "knitr", "devtools")
# Check if packages are not installed and assign the
# names of the packages not installed to the variable new.pkg
new.pkg <- pkg[!(pkg %in% installed.packages())]
# If there are any packages in the list that aren't installed,
# install them
if (length(new.pkg))
  install.packages(new.pkg, repos = "http://cran.rstudio.com")
# Load packages
library(dplyr)
library(ggplot2)
library(knitr)
```

# EvoMining {#rmd-basics}
## Introduction
Enzyme promiscuity on metabolic families, can be looked on enzymes that are over a divergent process.

## Gen families expansions on genomes
### Pangenomes
Expansions are located on pangenome, Tools to analyse pangenome BPgA  

## EvoMining
EvoMining looks expansions on prokariotic pangenome.  
Biological idea.   

EvoMining was available as a consult website with 230 members of the Actinobacteria phylum as genomic data base, 226 unclassified nBGCs, and not interchangable central database 339 queries for nine pathways, including amino acid biosynthesis, glycolysis, pentose phosphate pathway, and tricarboxylic acids cycle. [@cruz-morales_phylogenomic_2016] EvoMining was proved on Actinobacteria Arseno-lipids  

## Pangenome
The sequenced genome of an individull in some species is just a partil print of the species geneticll repertoire  Individualls can gain and loss genes.  
[@koonin_turbulent_2015] Pangenome is the total sequenced gene pool in a taxonomically related group.  Supergenome all the possible extant genes. About 10 times genomes. there are open, closed pangenomes.Most genomes has a core a shell and a unique genes.  
Gene history its a tree history  

HGT doubles mutation rate on prokarites.  
Maybe HGT is an selected feature, if is the case, so could be np production.  
Some archaeas has open pangenome.  [@halachev_calculating_2011]

HGT doubles mutation rate on prokarites.  [@koonin_turbulent_2015]
Maybe HGT is an selected feature, if is the case, so could be np production.  
Some archaeas has open pangenome.  [@halachev_calculating_2011]
Shell trees converge to core trees [@narechania_random_2012]

## EvoMining Implementation  
**EvoMining** was expanded from a website ([http://evodivmet.langebio.cinvestav.mx/EvoMining/index.html](http://evodivmet.langebio.cinvestav.mx/EvoMining/index.html)) with limited datasets to an easy to install distribution that allows flexiblibilty on genomic, central and natural product databases. Evomining user distribution was developed on perl on Ubuntu-14.04 but wraped on [Docker](https://www.docker.com/). Docker is a software containerization platform that allows repetibilty regardless of the environment. Docker engine is avilable for Linux, Cloud, macOS 10.10.3 Yosemite or newer and even 64bit Windows 10.

Dependencies that were packaged at EvoMining docker app are Apache2, muscle3.8.31, newick-utils-1.6,quicktree, blast-2.2.30, Gblocks_Linux64_0.91b perl and from cpan CGI, SVG and Statistics::Basic modules.  

Github defines itself as an online project hosting using Git. Its free for open source-code hosting and facilitates team work. Includes source-code browser, in-line editing, and wikis. 

Dockerhub is an apps project hosting. 

[Dockerhub nselem](https://hub.docker.com/u/nselem/)

EvoMining code is open source and it is available at a github repository [github/EvoMining](https://github.com/nselem/EvoMining)

Github and Dockerhub can be coneccted by the use of repositories automatically built. Among the advantages of automated builds are that the DockerHub repository is automatically kept up-to-date with code changes on GitHub and that its Dockerfile is available to anyone with access to the Docker Hub repository. EvoMining is stored on a DockerHub automated build repository linked to github EvoMining repository so that code is always actualized.

To download EvoMining image from docker Hub once Docker engine is installed its necessary to run the following command at a terminal:  
`docker pull nselem/newevomining`  

To run EvoMining container  
`docker run-i -t  -v /home/nelly/docker-evomining:/var/www/html -p 80:80 evomining /bin/bash`  

To start evoMining app
`perl startEvomining`  
``
Detailed tutorial, EvoMining description, pipeline and user guide are available at a wiki on github at [EvoMining wiki](https://github.com/nselem/EvoMining/wiki).

Other genomic apps were containerized to docker images during this work.  
- _myRAST_ docker- <https://github.com/nselem/myrast>  
RAST is a bacterial and Archaeal genome annotator [@aziz_rast_2008, @overbeek_seed_2014 , @brettin_rasttk:_2015]
This app allows myRAST functionality to upload  
It allows EvoMining genome database annotation.   
-_Orthocores_ docker-<https://github.com/nselem/orthocore>    
Helps to obtain genomic core paralog free and construct genomic trees  
-_CORASON_ docker-<https://github.com/nselem/EvoDivMet/wiki>    
-PseudoCore github- <>  
Genomic Core with a reference genome has the advantage of more genomes, but it is not paralog free    

-RadiCal docker image  
To detect core diferrences on a set of genomes  
-BPGA to analize pangenome  

EvoMining Dockerization was chosen to avoid future compatibilty problems, for example dependencies unavailabilty, or incompatibility between future versions of its software components. As much as reproducible research was a concerned while developing EvoMining app, reproducibilty is also important on data analysis, for that reason this document was writen using R-markdown and latex template from Reed College [@chesterismay_updated_2016]. While R-markdown allows to write and run R code and interpolate text paragraph to explain scripts and analysis.   

## EvoMining Databases  
Evomining containerized app is a user-interactive genomic tool dedicated to the study of protein function[].  

1. Genomes DB
2. Natural Products DB 
3. Central Pathways DB 

_Archaea_, _Actinobacteria_, _Cyanobacteria_ were used as genome DB, [MIBiG](http://mibig.secondarymetabolites.org/) was used as Natural Product DB and different Central Pathways were used.

#### Genome DB  
RAST annotation of genomes was done.  

#### Phylogeny  
```{r testingPhylogeny, echo=FALSE}
## I'm deciding if use ape or phyloseq, learning about two libraries
library(ape)
MyTree <- read.tree("chapter1/TREES/100Cyanos")
plot(MyTree, edge.width = 2,font = 0.1, edge.color = "blue",tip.color = "gray", adj=0)
```

To capture differences on genomes we sort them phylogenetically. Phylogenies can be constructed using different paradigms as Parsimony, Maximum Likelihood, and Bayesian inference. Short descriptions of the main phylogeny methods are included below.

Why is a tree useful {Book reference}
 why trees are useful for?  
* Distance methods  
* Parsimony
* Maximum Likelihood
* Mr bayes

General Trees  
Actinobacteria Tree, ArchaeaTree, CyanobacteriaTree.  

It's easy to create a list.  It can be unordered like

To create a sublist, just indent the values a bit (at least four spaces or a tab).  (Here's one case where indentation is key!)

1. Item 1
1. Item 2
1. Item 3
    - Item 3a
    - Item 3b  
    
#### Central DB  
We chose central pathways from [@barona-gomez_what_2012]  
* BBH 
Best Bidirectional Hits with studied enzymes from Central Actinobacterial pathways were selected.

* By abundance    

* By expansions on genomes

[largefiles,https://help.github.com/articles/installing-git-large-file-storage/]

##Data Bases
###Central pathways  
Central database were chosen by BBH from 
```{r BBH_organisms, results = "asis"}
table <- read.csv("chapter1/WC_Central/BBH_Organisms.txt", row.names = 1,sep="\t")
kable(table,  caption = "BBH_Organisms \\label{tab:BBH_Organisms}",caption.short = "BBH_Organisms ")
```
  
### Genome Dynamics  
Among BBH central databases, genomic dynamics was included.  
Whats change site:[WC Data](http://pubseed.theseed.org/wc.cgi?request=show_otus&base=/homes/nselem/Data/CS)  

groups were formed with 100Cyanos, 100Archaea , 118 Actinos Closed, 43StreptosClosed    
Selected organims were  

```{r WC_organisms, results = "asis"}
table <- read.csv("chapter1/WC_Central/WC_Organisms.txt", row.names = 1,sep="\t")
kable(table,  caption = "WC_Organisms \\label{tab:WC_Organisms}",caption.short = "WC_Organisms ")
```



Those families present on at least as much as genomes on the group    
Cyanos  100 647  
Abundant.Families.100Cyanos  
Actinos  118  132  
Abundant.Families.43Strepto  
Archaea  100  35  
Abundant.Families.Actinos  
Streptomyces  43  1263  
Abundant.Families.Archaeas  

Those families expanded on at least two groups  
`cat *Abun* | cut -f3| sort | uniq -c | sort >Abundance.all`  
<!--cut -f3 Abundant.Families.100Cyanos |sort >f3Cyanos-->
<!--Excel sorted-->
  
Those Families expanded on Archaea  and not expanded on Actino  
`comm -23 f3Archaeas f3Actinos >ArchaeasNoActinos`  
Those Families expanded on Actino and not on Archaea   
`comm -13 f3Archaeas f3Actinos >ActinosNoArchaea`  
  
Those families expanded on Streptomyces but not in ActinoBacteria   
`comm -13 f343Strepto f3Actinos >ActinosNoStrepto`  
Those Families expanded on Actinobacteria and not in Streptomyces   
` comm -23 f343Strepto f3Actinos >StreptoNoActinos `  

Those Families expanded on Cyano and not in Actino  
`comm -23 f3Cyanos f3Actinos >CyanosNoActinos`  
  





#### Natural Products DB  
Natural products was improved from previous version

### AntisMASH optional DB  
AntiSMASH is [@weber_antismash_2015,@medema_antismash:_2011]  
### Archaeas Results
Archaea is a kingdom of recent discovery were not many natural products has been known. On Actinobacteria, evoMining has proved its value to find new kinds of natural products. The clue to this discovery was that Actinobacteria has genomic expanssions. Now Archaea has genomic expansions, even more has central pathways genomic expansions. Are this expansions derived from  a genomic duplication?  
Has Archaea natural products detected by antismash, and if not, where are this NP's or may Archaea doesn't have NP's.

applying EvoMining to Archaea  

### Otras estrategias para los clusters Argon context Idea
##Argonne  
ssh nselem@login.mcs.anl.gov  
phrase  
ssh nselem@maple  
password  

cs close strain  
wc whats chain  
  
we source (edit bashrc)  
link ln (create a link to ross directory)  
run out of power:  
screen  
  
in Seqs (not mine)  
cat   
6666666.103569  6666666.112815  6666666.112823  6666666.112833  6666666.112841  6666666.112849  6666666.112857  > /home/nse/Concat_Full  
to find paralogous sets  
 svr_representative_sequences -b -f Id_Clust -s 0.5 < Concat_Full > TempFull&   
 perl -p -i -e 's/\r//' readable.tree to clean the tree  
To find contexts o pegs of paralogous sets  
  
Context midle point 5000 bp (using text tables)  
scp 6666666.112839.txt nselem@maple:/homes/nselem/Strepto_01/.  
  
fig|6666666.112839.peg.26  
  
copy families.all file  
on the file we have column1 family name column 5 peg id  
  
cluster_objects < elements_to_cluster > ClusteFile  
  
write a file with pegs  
1	peg1	adjacent1,	adjacent2 ....  
1	peg2  
2  
2  
   
write a file similiar but with the family number  
  
1	peg1	fn1,	fn2 ....  
1	peg2  
2  
2  
  
compare each peg on this file from the same family  
  
Write the conextions file  
peg1	peg2  
peg1 	peg3  
peg2	peg3  
  
cluster this file and score the cluster  
  
Define  
  
	1.  a "function set" is generated by the what's changed directory  
 as a "family"  
  
	2.  a "paralog set" is a set of function sets in which paralogous  
 members span the sets  
  
	3.  a PEG is in a paralog set if it is in one ofthe function sets  
 that make up the  
  
	4.  a "context" of a PEG is the set of close pegs  
	4.1 First cluster operation would give us: context sets  (CS)  
  
	5.  a "context set" is a set of PEGs with "similar contexts"  
	5.1 second clustering operation would give us:cluster  (Cl)  
  
	6.  a "cluster" is a set of context sets (each context set is a different   
	
  
compute:  
	Compute the context sets that are made from PEGs that occur in PS.  
	Compute the contexts of PEGs in PS.   
  
cluster these context using the "similar contexts" relation  
  
This gives a set of clusters, and the members of the clusters are context sets  
That is, a cluster is a set of context sets  
  
        
      a. the number of contexts sets i  
  
score the clusters  
	Take a paralog set PS.   
	Be the context sets: CS_1, CS_2,..., CS_k members of the paralogous set   
	k the number of contexts sets on the paralogous set  
	n_i the cardinality of CS_i  
  
	PS={CS1,CS2,...,CS3}  
	Cl={[CS_1,n_1],[CS_2,n_2],...,[CS_k,n_k]}  

	let be M=max(n_i)   i=1,2,..k (Maximum cardinality of Context sets)  
       	m=max(n_i)   i=1,2,..k, i!=M (second greatest cardinality of context sets)  
       	(We are intersted that a second copy is distributed)  

	We are interested on k,M,n to form a scoring function for the cluster set  
	S=f(k,m,M)=c_1*k+c_2*m+c_3*M  
  
  
############## history
Para hacer un nuevo set de datos	  

 591  cd Data/CS  
  592  mkdir Directorio  
  593  vi Directorio/rep.genomes  
  594  cd Directorio/  
  600  nohup svr_CS -d Directorio&  

Contenido de rep.genomes  
rast|390693     nselem35        q8Vf6ib  
rast|390675     nselem35        q8Vf6ib  
rast|388811     nselem35        q8Vf6ib  
  


When you click the **Knit** button above a document will be generated that includes both content as well as the output of any embedded **R** code chunks within the document. You can embed an **R** code chunk like this (`cars` is a built-in **R** dataset):

```{r cars}
summary(cars)
```

### Inline code

If you'd like to put the results of your analysis directly into your discussion, add inline code like this:

> The `cos` of $2 \pi$ is `r cos(2*pi)`. 

Another example would be the direct calculation of the standard deviation:

> The standard deviation of `speed` in `cars` is `r sd(cars$speed)`.

One last neat feature is the use of the `ifelse` conditional statement which can be used to output text depending on the result of an **R** calculation:

> `r ifelse(sd(cars$speed) < 6, "The standard deviation is less than 6.", "The standard deviation is equal to or greater than 6.")`

Note the use of `>` here, which signifies a quotation environment that will be indented.

As you see with `$2 \pi$` above, mathematics can be added by surrounding the mathematical text with dollar signs.  More examples of this are in [Mathematics and Science] if you uncomment the code in [Math].  

## Recomendaciones de Luis
Para evoMining   
Probar distintos métodos de filogenia y después hacer la coloración.   
maximum likelihood, Protest phyml  
Atracción de ramas largas.  
raxml  
trim all vs Gblocs (Tony Galvadon)  

Comparar dos árboles  
Para ver si la evolución de los genes concatenados ha sido simultánea   
Robinson and foulds   
Joe Felsestein  
Phylip  

2. dist tree  
quarter descomposition  
peter gogarten fendou Mao  

Sets de experimentos.  
Para el experimento de los streptomyces con ruta centrales el core, analizar el problema de dominios   múltiples.  
Dominios  
Nan Song, Dannie durand  
Después del blast  


Para obtener   
Pablo Vinuesa: Get Homologues  

Burkhordelias y su toxina (Preguntar a Beto)  
Cianobacterias y la ruta de fijación de nitrógeno.  

Servidor Viernes a las 12:00   

## CORASON: Other genome Mining tools context-based
 
##CORe Analysis of Syntenic Orthologs to prioritize Natural Product-Biosynthetic Gene Cluster  
Bacterial biosynthetic gene clusters (BGCs) known are always increasing, almost all bacterial genome sequenced contributes with new genes and gene clusters to the known Bacterial Pangenome. In consequence of gene diversity and sequence technology advances researchers often have a large set of genomes to analize in search of a particular gene cluster variation. Answering BGCs analysis needs, CORASON allows users to find and visualice variations of a given gene cluster sorting them according to the conserved core cluster phylogeny.   
     
The core genome on a taxonomical group is the set of coding sequences that are shared between all group members, this definition may be adapted to the cluster core by exploring a set of gene clusters instead of a set of genomes. The cluster core attempts to identify a set of functions conserved on a particular BGC variations.  A report about gene function using RAST technology will be provided whenever a cluster core exists and core sequences will be concatenated to construct a phylogenetic tree and sort variation clusters accordingly.     

To find cluster variations, given a query protein sequence that belongs to a reference cluster, CORASON will search on a Bacterial genome database all gene clusters that contains orthologues of the query-protein and at least another sequence from the reference cluster. Orthologues on variation clusters are coloured within a gradient according to its identity percentage with the reference cluster sequences.   
     
Finally, in order to provide an easy to install distribution, CORASON was packaged on docker containerization platform. Software dependencies such as BLAST 2.2.30, muscle3.8.3, GBlocksLinux64_0.91b, quicktree, newick-utils-1.6, and CORASON code were wrapped together on CORASON docker container. [Tutorial](https://github.com/nselem/EvoDivMet/wiki) and software are available at nselem/github. 

CORASON inputs are a genomic database, a reference cluster and an enzyme inside this cluster, outputs are newick trees, core functional report and a cluster variation SVG file. SVG format among being high quality scalable graphics, also allow to display metadata such as gene function and genome coordinates just by mouse over figures on a browser facilitating genomic analysis.  

In conclusion CORASON is an easy to install comparative genomic visual tool on a customizable genome database that allows users to visualice variations of a reference gene cluster identifing its core functions and finally sorting variations according to their evolutionary history helping to prioritize clusters that may be involved on chemical novelty. 

