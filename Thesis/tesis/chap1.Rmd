---
output: pdf_document
---
<!--
The {#rmd-basics} text after the chapter declaration will allow us to link throughout the document back to the beginning of Chapter 1.  These labels will automatically be generated (if not specified) by changing the spaces to hyphens and capital letters to lowercase.  Look for the reference to this label at the beginning of Chapter 2.
-->

# EvoMining {#rmd-basics}
## Introduction
Enzyme promiscuity on metabolic families, can be looked on enzymes that are over a divergent process.

## Gen families expansions on genomes
### Pangenomes
Expansions are located on pangenome, Tools to analyse pangenome BPgA  

## EvoMining
EvoMining looks expansions on prokariotic pangenome.  
Biological idea.   

EvoMining was available as a consult website with 230 members of the Actinobacteria phylum as genomic data base, 226 unclassified nBGCs, and not interchangable central database 339 queries for nine pathways, including amino acid biosynthesis, glycolysis, pentose phosphate pathway, and tricarboxylic acids cycle. [@cruz-morales_phylogenomic_2016] EvoMining was proved on Actinobacteria Arseno-lipids  

## Pangenome
The sequenced genome of an individull in some species is just a partil print of the species geneticll repertoire  Individualls can gain and loss genes.  
[@koonin_turbulent_2015] Pangenome is the total sequenced gene pool in a taxonomically related group.  Supergenome all the possible extant genes. About 10 times genomes. there are open, closed pangenomes.Most genomes has a core a shell and a unique genes.  
Gene history its a tree history  
<<<<<<< HEAD
HGT doubles mutation rate on prokarites.  
Maybe HGT is an selected feature, if is the case, so could be np production.  
Some archaeas has open pangenome.  [@halachev_calculating_2011]
=======
HGT doubles mutation rate on prokarites.  [@koonin_turbulent_2015]
Maybe HGT is an selected feature, if is the case, so could be np production.  
Some archaeas has open pangenome.  [@halachev_calculating_2011]
Shell trees converge to core trees [@narechania_random_2012]
>>>>>>> 86d01d8784a6d89912c3b8db86ea6753d5074760
### Implementation  
In order to expand **EvoMining** from a consulting website to a user-interactive genomic tool, code was developed on perl and packaged as a docker distribution. Docker is a software containerization platform that guarantee reptibilty and easy instalation.  

[EvoMining wiki](https://github.com/nselem/EvoMining/wiki) 
[Dockerhub nselem](https://hub.docker.com/u/nselem/)
[Docker](https://www.docker.com/)  
[CORASON](https://github.com/nselem/EvoDivMet/wiki)
[myRAST docker](https://github.com/nselem/myrast)
[Orthocores docker](https://github.com/nselem/orthocore)
_Archaea_, _Actinobacteria_, _Cyanobacteria_ were used as genome DB, [MIBiG](http://mibig.secondarymetabolites.org/) was used as Natural Product DB and different Central Pathways were used.

**EvoMining** needs. Functional genomics uses genomes in the study of gene and protein function[].
1. Genomes DB
2. Natural Products DB 
3. Central Pathways DB 

#### Genome DB  
RAST annotation of genomes was done.  

#### Phylogeny  
```{r testingPhylogeny, echo=FALSE}
## I'm deciding if use ape or phyloseq, learning about two libraries
library(ape)
MyTree <- read.tree("chapter1/TREES/100Cyanos")
plot(MyTree, edge.width = 2,font = 0.1, edge.color = "blue",tip.color = "gray", adj=0)
```

To capture differences on genomes we sort them phylogenetically. Phylogenies can be constructed using different paradigms as Parsimony, Maximum Likelihood, and Bayesian inference. Short descriptions of the main phylogeny methods are included below.
<<<<<<< HEAD
=======
Why is a tree useful {Book reference}
>>>>>>> 86d01d8784a6d89912c3b8db86ea6753d5074760
 why trees are useful for?  
* Distance methods  
* Parsimony
* Maximum Likelihood
* Mr bayes

General Trees  
Actinobacteria Tree, ArchaeaTree, CyanobacteriaTree.  

It's easy to create a list.  It can be unordered like

To create a sublist, just indent the values a bit (at least four spaces or a tab).  (Here's one case where indentation is key!)

1. Item 1
1. Item 2
1. Item 3
    - Item 3a
    - Item 3b  
    
#### Central DB  
We chose central pathways from [@barona-gomez_what_2012]  
* BBH 
Best Bidirectional Hits with studied enzymes from Central Actinobacterial pathways were selected.

* By abundance    

* By expansions on genomes

[largefiles,https://help.github.com/articles/installing-git-large-file-storage/]

#### Natural Products DB  
Natural products was improved from previous version


### Archaeas Results
Archaea is a kingdom of recent discovery were not many natural products has been known. On Actinobacteria, evoMining has proved its value to find new kinds of natural products. The clue to this discovery was that Actinobacteria has genomic expanssions. Now Archaea has genomic expansions, even more has central pathways genomic expansions. Are this expansions derived from  a genomic duplication?  
Has Archaea natural products detected by antismash, and if not, where are this NP's or may Archaea doesn't have NP's.

applying EvoMining to Archaea  

### Otras estrategias para los clusters Argon context Idea
Argon
When you click the **Knit** button above a document will be generated that includes both content as well as the output of any embedded **R** code chunks within the document. You can embed an **R** code chunk like this (`cars` is a built-in **R** dataset):

```{r cars}
summary(cars)
```

### Inline code

If you'd like to put the results of your analysis directly into your discussion, add inline code like this:

> The `cos` of $2 \pi$ is `r cos(2*pi)`. 

Another example would be the direct calculation of the standard deviation:

> The standard deviation of `speed` in `cars` is `r sd(cars$speed)`.

One last neat feature is the use of the `ifelse` conditional statement which can be used to output text depending on the result of an **R** calculation:

> `r ifelse(sd(cars$speed) < 6, "The standard deviation is less than 6.", "The standard deviation is equal to or greater than 6.")`

Note the use of `>` here, which signifies a quotation environment that will be indented.

As you see with `$2 \pi$` above, mathematics can be added by surrounding the mathematical text with dollar signs.  More examples of this are in [Mathematics and Science] if you uncomment the code in [Math].  


## CORASON: Other genome Mining tools context-based
 
### CORASoN
You can also embed plots.  For example, here is a way to use the base **R** graphics package to produce a plot using the built-in `pressure` dataset:

```{r pressure, echo = FALSE, cache = TRUE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the **R** code that generated the plot.  There are plenty of other ways to add chunk options.  More information is available at <http://yihui.name/knitr/options/>.  

Another useful chunk option is the setting of `cache = TRUE` as you see here.  If document rendering becomes time consuming due to long computations or plots that are expensive to generate you can use knitr caching to improve performance.  Later in this file, you'll see a way to reference plots created in **R** or external figures.

## Loading and exploring data

Included in this template is a file called `flights.csv`.  This file includes a subset of the larger dataset of information about all flights that departed from Seattle and Portland in 2014.  More information about this dataset and its **R** package is available at <http://github.com/ismayc/pnwflights14>.  This subset includes only Portland flights and only rows that were complete with no missing values.  Merges were also done with the `airports` and `airlines` data sets in the `pnwflights14` package to get more descriptive airport and airline names.

We can load in this data set using the following command:

```{r load_data}
flights <- read.csv("data/flights.csv")
```

The data is now stored in the data frame called `flights` in **R**.  To get a better feel for the variables included in this dataset we can use a variety of functions.  Here we can see the dimensions (rows by columns) and also the names of the columns.

```{r str}
dim(flights)
names(flights)
```

Another good idea is to take a look at the dataset in table form.  With this dataset having more than 50,000 rows, we won't explicitly show the results of the command here.  I recommend you enter the command into the Console **_after_** you have run the **R** chunks above to load the data into **R**.

```{r view_flights, eval = FALSE}
View(flights)
```

While not required, it is highly recommended you use the `dplyr` package to manipulate and summarize your data set as needed.  It uses a syntax that is easy to understand using chaining operations.  Below I've created a few examples of using `dplyr` to get information about the Portland flights in 2014.  You will also see the use of the `ggplot2` package, which produces beautiful, high-quality academic visuals.

We begin by checking to ensure that needed packages are installed and then we load them into our current working environment:

```{r load_pkgs, message = FALSE}
# List of packages required for this analysis
pkg <- c("dplyr", "ggplot2", "knitr", "devtools")
# Check if packages are not installed and assign the
# names of the packages not installed to the variable new.pkg
new.pkg <- pkg[!(pkg %in% installed.packages())]
# If there are any packages in the list that aren't installed,
# install them
if (length(new.pkg))
  install.packages(new.pkg, repos = "http://cran.rstudio.com")
# Load packages
library(dplyr)
library(ggplot2)
library(knitr)
```

The example we show here does the following:

- Selects only the `carrier_name` and `arr_delay` from the `flights` dataset and then assigns this subset to a new variable called `flights2`. 

- Using `flights2`, we determine the largest arrival delay for each of the carriers.

```{r max_delays}
flights2 <- flights %>% dplyr::select(carrier_name, arr_delay)
max_delays <- flights2 %>% group_by(carrier_name) %>%
  summarize(max_arr_delay = max(arr_delay, na.rm = TRUE))
```

We next introduce a useful function in the `knitr` package for making nice tables in _R Markdown_ called `kable`.  It produces the \LaTeX\ code required to make the table and is much easier to use than manually entering values into a table by copying and pasting values into Excel or \LaTeX.  This again goes to show how nice reproducible documents can be!  There is no need to copy-and-paste values to create a table.  (Note the use of `results = "asis"` here which will produce the table instead of the code to create the table.  You'll learn more about the `\\label` later.)  The `caption.short` argument is used to include a shorter version of the title to appear in the List of Tables at the beginning of the document.

```{r table_out, results = "asis"}
kable(max_delays, col.names = c("Airline", "Max Arrival Delay"),
      caption = "Maximum Delays by Airline \\label{tab:max_delay}",
      caption.short = "Max Delays by Airline")
```

We can further look into the properties of the largest value here for American Airlines Inc.  To do so, we can isolate the row corresponding to the arrival delay of 1539 minutes for American in our original `flights` dataset.

```{r max_props}
flights %>% dplyr::filter(arr_delay == 1539, 
                   carrier_name == "American Airlines Inc.") %>%
  dplyr::select(-c(month, day, carrier, dest_name, hour, 
            minute, carrier_name, arr_delay))
```

We see that the flight occurred on March 3rd and departed a little after 2 PM on its way to Dallas/Fort Worth.  Lastly, we show how we can visualize the arrival delay of all departing flights from Portland on March 3rd against time of departure.

```{r march3plot, fig.height = 3, fig.width = 6}
flights %>% dplyr::filter(month == 3, day == 3) %>%
  ggplot(aes(x = dep_time, y = arr_delay)) +
  geom_point()
```

## Additional resources

- _Markdown_ Cheatsheet - <https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet>

- _R Markdown_ Reference Guide - <https://www.rstudio.com/wp-content/uploads/2015/03/rmarkdown-reference.pdf>

- Introduction to `dplyr` - <https://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html>

- `ggplot2` Documentation - <http://docs.ggplot2.org/current/>
